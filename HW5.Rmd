---
title: 'Selected Topics of Psychometrics (NMST570)'
subtitle: 'Homework Assignment 5: IRT models'
author: 'Kateřina Hudáčová (Benjamín Kunc)'
date: \today
output:
  html_document:
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
    fig_caption: yes
    df_print: paged
    code_folding: show
---

Note: The assignment is due on December 13, 2021. Send your code and html/pdf report to `dlouha@cs.cas.cz` (and to `martinkova@cs.cas.cz` in copy).

</br>

#### 1. Read and comment on Chapter 5, 6, and 7 on https://perusall.com. [2 pts]

#### 2. Run the code for the Chapter 5, 6, and 7, available on course webpage http://www.cs.cas.cz/martinkova/NMST570.html.

#### 3. Complete the CAPlearnR online tutorials for IRT models. Attach certificates. [4 pts] 
> Note: If you meet any issues, contact the the TA or the instructor before 8 AM of the due date.

#### 4. Project preparation.
##### Explore the Czech matura data OR DATA OF YOUR CHOICE as described below. You can work with 1-2 teammates on this task. All teammate names have to be included on your answer sheet. [4 pts]

I am working with the `BFI2` dataset from the `ShinyItemAnalysis` package. The `BFI2` dataset contains responses of $1733$ Czech respondents to the Big Five Inventory 2, as well as information about their age, education, and gender. The BFI2 items are scored using a 5-point Likert scale. For the purpose of this assignment I will only be using the extraversion items of the `BFI2`.

```{r load packages, include=FALSE}
library(ShinyItemAnalysis)
library(ggplot2)
library(dplyr)
library(ltm)
library(mirt)
library(eRm)
```


```{r load_data, message=FALSE, warning=FALSE}
data(BFI2, package='ShinyItemAnalysis')

# Data frames for domains
BFI2_e <- BFI2[, seq(1, 56, 5)]
```

I created datasets for the extraversion dimension.

</br>

#### 4a. 1PL IRT model for binary data. 
##### Binarize your data and fit 1PL IRT model. Plot and discuss a Person-Item map (Wright map). 

I binarized the extraversion dimension of the`BFI2` data and fit a Rasch model using the `mirt` package. 

```{r 1PLirt}
# binarize data
bin <- function(x) {
  ifelse(x %in% 4:5, 1, 0)
}

BFI2_e_bin <- data.frame(lapply(BFI2_e, bin))

# fit model
fit_rasch <- mirt::mirt(data = BFI2_e_bin, model = 1, itemtype = "Rasch", SE = TRUE)

# intercept/slope parameter estimates
coef(fit_rasch, SE = TRUE)

# IRT parameter estimates
coef(fit_rasch, SE = TRUE, IRTpars = TRUE)

# ICCs
plot(fit_rasch, type = "trace", facet_items = FALSE)

# TSC
plot(fit_rasch)

# factor scores
fs_SE <- mirt::fscores(fit_rasch, full.scores.SE = TRUE)
head(fs_SE, 3)

# first respondent
summary(fs_SE[, 1])
sd(fs_SE[, 1])

# Wright map
b <- coef(fit_rasch, simplify = TRUE, IRTpars = TRUE)$items[, "b"]
ggWrightMap(fs_SE[, 1], b)
```

As we can see from the parameter estimates, the ability variance is estimated at $1.97$ with a confidence interval of $1.78; 2.16$. For item 31 (most difficult item, *"Považuji se za někoho, kdo je někdy plachý, introvertní."*) an ability (extraversion) of almost 1.1 SD above the mean is required to answer *"Disagree strongly"* or *"Disagree a little"* (reversed item) with a $50\%$ probability. The first respondent in this dataset has an ability (extraversion) of $1.47 + / - 0.66$ and the model discrimination is estimated at $1.24$.
</br>

The Wright map confirms that item 7 of the extraversion dimension (coded as item 31) is the most difficult and item 3 (coded as item 11, *"Považuji se za někoho, kdo zřídkakdy pociťuje vzrušení a nadšení pro věc."*) is the least difficult.

</br>

#### 4b. Other IRT models, model selection 
##### Fit more IRT models (2PL, 3PL/4PL only if they make sense) including models for ordinal data, if ordinal items are present in your dataset. Select optimal model: Provide reasoning for selected IRT model (based on data type or using comparison of more IRT models). Provide model equation(s) and interpretation of parameters. Which method was used for estimation of parameters? 

I decided to fit cummulative logit IRT models -- graded response model and graded ratings scale model -- since I'm working with ordinal items based on a Likert scale which also remains the same for all items.

```{r IRTmodel}
# GRM
fit_GRM <- mirt::mirt(BFI2_e, model = 1, itemtype = "graded")
coef(fit_GRM)

# GRSM
fit_GRSM <- mirt::mirt(BFI2_e, model = 1, itemtype = "grsmIRT")
coef(fit_GRSM, simplify = TRUE)

# model comparison
anova(fit_GRM, fit_GRSM)
```

It seems that the restricted model (GRSM) is a better fit for this data.
Equation: ${\pi\ast}_{pik} = P(Y_{pi} \geq k|\theta_p) = \frac{\exp(a_i(\theta_p - (b_i + \lambda_k)))}{1 + \exp(a_i(\theta_p - (b_i + \lambda_k)))}$
Parameter $a_1$ represents the item-specific slope and parameter $c$ corresponds to the item-specific location.
</br>

#### 4c. Item parameters
##### Plot item characteristic curves, item information curves, test information curve. Provide table of model parameter estimates and their standard errors, or confidence intervals. Which item is most informative for ability level 1SD above average?

I used the `itemplot` function from the `mirt` package to plot ICCs of items 3 (i11) and 7 (i31). For IIC and TIC I used the plot function.

```{r ItemParameters}
# category response curves
mirt::itemplot(fit_GRSM, item = 3, type = "infotrace")
mirt::itemplot(fit_GRSM, item = 7, type = "infotrace")

# item information curves
plot(fit_GRSM, type = "infotrace", facet_items = FALSE)

# test information curve
plot(fit_GRSM, type = "infoSE")

coef(fit_GRSM)

# 1SD above avg item information
testinfo(fit_GRSM, 1, individual = TRUE)
```

The slope for items 3 (i11) and 7 (i31) are quite similar, but it seems that even respondents with lower latent extraversion tend to disagree with item 3 (*"Považuji se za někoho, kdo zřídkakdy pociťuje vzrušení a nadšení pro věc."*). The last item (i56) is the most informative for extraversion level 1SD above average.
</br>

#### 4d. Ability estimates
##### Provide ability estimate for the first respondent, including the standard error or confidence interval. Plot relationship between ability estimates in IRT models and traditional ability estimates based on (standardized) total scores.

For the ability estimate I used the `fscores` function from the `mirt` package.

```{r AbilityEstimates}
fs_SE <- mirt::fscores(fit_GRSM, full.scores.SE = TRUE)

fs_SE[1,]
summary(fs_SE[1,])

fs <- mirt::fscores(fit_GRSM)
sts <- as.vector(scale(rowSums(BFI2_e)))

# plot
plot(fs ~ sts, xlab = "Standardized total score", ylab = "Factor score")
cor(fs, sts)

```

The ability of the first respondent is estimated at $1.017$ with a standard error of $0.35$ and a confidence interval of $0.35; 1.02$.

</br>

#### 4e. (extra) Interactive ShinyItemAnalysis app.
##### Use the interactive ShinyItemAnalysis application to create a report with selected IRT model. If your data is too large, consider using sample data (e.g. from a random sample of 2000 respondents and selection of items - single domain, etc.).

Your text (description of methods).

</br>


#### 5. Use/discuss your own data and/or provide constructive feedback to the lecture, exercises, or any of the material. [BONUS 1 pt]

Your text.

</br>
